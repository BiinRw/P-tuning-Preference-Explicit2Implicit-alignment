#!/usr/bin/env python3
"""
æµ‹è¯•é¢„å½’ä¸€åŒ–ä¿®å¤çš„è„šæœ¬
ä¸»è¦æµ‹è¯•æ•°æ®ç±»å‹å…¼å®¹æ€§é—®é¢˜
"""
import torch
import torch.nn.functional as F


def test_quantile_dtype_compatibility():
    """æµ‹è¯•torch.quantileå¯¹ä¸åŒæ•°æ®ç±»å‹çš„æ”¯æŒ"""
    print("ğŸ§ª æµ‹è¯•torch.quantileæ•°æ®ç±»å‹å…¼å®¹æ€§...")
    
    # æ¨¡æ‹Ÿä¸åŒçš„æ•°æ®ç±»å‹
    dtypes_to_test = [torch.float32, torch.float16, torch.bfloat16, torch.float64]
    
    for dtype in dtypes_to_test:
        print(f"\n  æµ‹è¯•æ•°æ®ç±»å‹: {dtype}")
        try:
            # åˆ›å»ºæµ‹è¯•æ•°æ®
            test_tensor = torch.randn(100, dtype=dtype)
            
            # æµ‹è¯•ç›´æ¥ä½¿ç”¨quantile
            try:
                q75_direct = torch.quantile(test_tensor, 0.75)
                print(f"    âœ… ç›´æ¥quantileæˆåŠŸ: {q75_direct:.4f}")
            except Exception as e:
                print(f"    âŒ ç›´æ¥quantileå¤±è´¥: {e}")
            
            # æµ‹è¯•è½¬æ¢ä¸ºfloatåä½¿ç”¨quantile
            try:
                test_tensor_float = test_tensor.float()
                q75_float = torch.quantile(test_tensor_float, 0.75)
                print(f"    âœ… è½¬æ¢ä¸ºfloatåquantileæˆåŠŸ: {q75_float:.4f}")
            except Exception as e:
                print(f"    âŒ è½¬æ¢ä¸ºfloatåquantileå¤±è´¥: {e}")
                
        except Exception as e:
            print(f"    âŒ åˆ›å»º{dtype}ç±»å‹tensorå¤±è´¥: {e}")


def simulate_pre_normalize_logps():
    """æ¨¡æ‹Ÿé¢„å½’ä¸€åŒ–å‡½æ•°çš„æ ¸å¿ƒé€»è¾‘"""
    print("\nğŸ§ª æµ‹è¯•é¢„å½’ä¸€åŒ–å‡½æ•°é€»è¾‘...")
    
    # æ¨¡æ‹Ÿembedding vs hard promptçš„åˆ†å¸ƒå·®å¼‚
    # æ¨¡æ‹Ÿhard promptçš„logæ¦‚ç‡ (è¾ƒå°èŒƒå›´)
    policy_chosen_logps = torch.randn(10, dtype=torch.float16) * 0.5  # [-1, 1]èŒƒå›´
    policy_rejected_logps = torch.randn(10, dtype=torch.float16) * 0.5
    
    # æ¨¡æ‹Ÿembedding promptçš„logæ¦‚ç‡ (è¾ƒå¤§èŒƒå›´)
    policy_pref_chosen_logps = torch.randn(10, dtype=torch.float16) * 20 - 50  # [-70, -30]èŒƒå›´
    policy_pref_rejected_logps = torch.randn(10, dtype=torch.float16) * 20 - 50
    
    print(f"åŸå§‹æ•°æ®èŒƒå›´:")
    print(f"  Base chosen: [{policy_chosen_logps.min():.4f}, {policy_chosen_logps.max():.4f}]")
    print(f"  Pref chosen: [{policy_pref_chosen_logps.min():.4f}, {policy_pref_chosen_logps.max():.4f}]")
    
    # æµ‹è¯•åˆ†å¸ƒæ„ŸçŸ¥çš„å½’ä¸€åŒ–ç­–ç•¥
    try:
        # å­˜å‚¨åŸå§‹æ•°æ®ç±»å‹
        original_dtype = policy_chosen_logps.dtype
        original_device = policy_chosen_logps.device
        
        # è½¬æ¢ä¸ºfloatè¿›è¡Œè®¡ç®—
        base_logps = torch.cat([policy_chosen_logps, policy_rejected_logps]).float()
        pref_logps = torch.cat([policy_pref_chosen_logps, policy_pref_rejected_logps]).float()
        
        base_mean, base_std = base_logps.mean(), base_logps.std() + 1e-8
        pref_mean, pref_std = pref_logps.mean(), pref_logps.std() + 1e-8
        
        base_range = base_logps.max() - base_logps.min()
        pref_range = pref_logps.max() - pref_logps.min()
        
        print(f"\nåˆ†å¸ƒç»Ÿè®¡:")
        print(f"  Base: mean={base_mean:.4f}, std={base_std:.4f}, range={base_range:.4f}")
        print(f"  Pref: mean={pref_mean:.4f}, std={pref_std:.4f}, range={pref_range:.4f}")
        
        # åº”ç”¨å½’ä¸€åŒ–ç­–ç•¥
        if pref_range > base_range * 2:  # Pref has much larger range
            print(f"\næ£€æµ‹åˆ°Prefåˆ†å¸ƒèŒƒå›´æ›´å¤§ï¼Œåº”ç”¨å½’ä¸€åŒ–...")
            
            target_mean, target_std = base_mean, base_std
            
            # ä½¿ç”¨robust scaling
            pref_median = pref_logps.median()
            pref_q75 = torch.quantile(pref_logps, 0.75)
            pref_q25 = torch.quantile(pref_logps, 0.25)
            pref_iqr = pref_q75 - pref_q25 + 1e-8
            
            scale_factor = target_std / (pref_iqr / 1.349)
            
            policy_pref_chosen_logps_norm = (policy_pref_chosen_logps.float() - pref_median) * scale_factor + target_mean
            policy_pref_rejected_logps_norm = (policy_pref_rejected_logps.float() - pref_median) * scale_factor + target_mean
            
            policy_chosen_logps_norm = policy_chosen_logps.float()
            policy_rejected_logps_norm = policy_rejected_logps.float()
            
            # è½¬æ¢å›åŸå§‹æ•°æ®ç±»å‹
            policy_chosen_logps_norm = policy_chosen_logps_norm.to(dtype=original_dtype)
            policy_rejected_logps_norm = policy_rejected_logps_norm.to(dtype=original_dtype)
            policy_pref_chosen_logps_norm = policy_pref_chosen_logps_norm.to(dtype=original_dtype)
            policy_pref_rejected_logps_norm = policy_pref_rejected_logps_norm.to(dtype=original_dtype)
            
            print(f"å½’ä¸€åŒ–åèŒƒå›´:")
            print(f"  Base chosen: [{policy_chosen_logps_norm.min():.4f}, {policy_chosen_logps_norm.max():.4f}]")
            print(f"  Pref chosen: [{policy_pref_chosen_logps_norm.min():.4f}, {policy_pref_chosen_logps_norm.max():.4f}]")
            
            # æµ‹è¯•log ratioè®¡ç®—
            pi_logratios_raw = policy_chosen_logps_norm - policy_rejected_logps_norm
            pi_pref_logratios_raw = policy_pref_chosen_logps_norm - policy_pref_rejected_logps_norm
            
            print(f"\nLog ratiosèŒƒå›´:")
            print(f"  Base ratios: [{pi_logratios_raw.min():.4f}, {pi_logratios_raw.max():.4f}]")
            print(f"  Pref ratios: [{pi_pref_logratios_raw.min():.4f}, {pi_pref_logratios_raw.max():.4f}]")
            
            print("âœ… é¢„å½’ä¸€åŒ–æµ‹è¯•æˆåŠŸï¼")
        else:
            print("â„¹ï¸  åˆ†å¸ƒèŒƒå›´ç›¸ä¼¼ï¼Œä¸éœ€è¦ç‰¹æ®Šå½’ä¸€åŒ–")
            
    except Exception as e:
        print(f"âŒ é¢„å½’ä¸€åŒ–æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹æµ‹è¯•é¢„å½’ä¸€åŒ–ä¿®å¤...")
    print("="*50)
    
    test_quantile_dtype_compatibility()
    simulate_pre_normalize_logps()
    
    print("\n" + "="*50)
    print("ğŸ‰ æµ‹è¯•å®Œæˆï¼")
