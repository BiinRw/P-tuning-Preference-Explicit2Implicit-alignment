#!/bin/bash

# ğŸ§ª DeepSpeedå‘½ä»¤æµ‹è¯•è„šæœ¬
echo "ğŸ§ª æµ‹è¯•DeepSpeedè®­ç»ƒå‘½ä»¤æ„å»º..."

cd /home/wangbinrui/research_projects/llama_rlhf/code

# æ¨¡æ‹Ÿfast_train.shä¸­çš„å…³é”®å˜é‡
TRAINING_MODE="embedding"
PROMPT_EMBEDDING_PATH="/home/wangbinrui/research_projects/llama_rlhf/code/Ptuning/ptuning_outputs/qwen2.5-1.5b_vtokens10_initnatural_language_kl0.1_margin0.05_lr1e-5_ep10_bs2_20250528_133602/checkpoint-32600/prompt_embeddings.pt"

POLICY_MODEL_PATH="Qwen/Qwen2.5-1.5B-Instruct"
REFERENCE_MODEL_PATH="Qwen/Qwen2.5-1.5B-Instruct"
TRAIN_DATASET_PATH="/home/wangbinrui/research_projects/llama_rlhf/datasets/ultrafeedback_binarized/train_prefs_ultrafeedback_binarized.jsonl"
TEST_DATASET_PATH="/home/wangbinrui/research_projects/llama_rlhf/datasets/ultrafeedback_binarized/test_prefs_ultrafeedback_binarized.jsonl"

BETA=0.05
ALPHA=0.1
LEARNING_RATE=5e-4
NUM_EPOCHS=1
GRADIENT_ACCUM_STEPS=512
MAX_LENGTH=300
MAX_PROMPT_LENGTH=128
LORA_R=16
LORA_ALPHA=32
LORA_DROPOUT=0.1
OUTPUT_DIR="./model_output/Preference_Guided_Ptuning"
WANDB_PROJECT="Preference_Guided_Ptuning"

# ğŸ–¥ï¸ GPUèŠ‚ç‚¹é…ç½® (å¯æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹)
GPU_NODES="localhost:1,2"  # å¯ä¿®æ”¹ä¸º: "localhost:0,1", "localhost:2,3", "localhost:0,1,2,3" ç­‰

# æ„å»ºå‘½ä»¤ (ä¸fast_train.shç›¸åŒçš„é€»è¾‘)
DEEPSPEED_CMD="CUDA_ALLOC_CONF=expandable_segments deepspeed --include=$GPU_NODES"
TRAIN_SCRIPT="train_with_preference_prompt.py"

ARGS="--policy-model-path $POLICY_MODEL_PATH"
ARGS="$ARGS --reference-model-path $REFERENCE_MODEL_PATH"
ARGS="$ARGS --dataset-path $TRAIN_DATASET_PATH"
ARGS="$ARGS --test-dataset-path $TEST_DATASET_PATH"
ARGS="$ARGS --beta $BETA"
ARGS="$ARGS --alpha $ALPHA"
ARGS="$ARGS --learning-rate $LEARNING_RATE"
ARGS="$ARGS --num-train-epochs $NUM_EPOCHS"
ARGS="$ARGS --gradient-accumulation-steps $GRADIENT_ACCUM_STEPS"
ARGS="$ARGS --max-length $MAX_LENGTH"
ARGS="$ARGS --max-prompt-length $MAX_PROMPT_LENGTH"
ARGS="$ARGS --lora-r $LORA_R"
ARGS="$ARGS --lora-alpha $LORA_ALPHA"
ARGS="$ARGS --lora-dropout $LORA_DROPOUT"
ARGS="$ARGS --output-dir $OUTPUT_DIR"
ARGS="$ARGS --wandb-project $WANDB_PROJECT"

# æ ¹æ®è®­ç»ƒæ¨¡å¼æ·»åŠ å‚æ•°
if [ "$TRAINING_MODE" = "embedding" ]; then
    ARGS="$ARGS --use-prompt-embedding --prompt-embedding-path $PROMPT_EMBEDDING_PATH"
fi

FULL_CMD="$DEEPSPEED_CMD $TRAIN_SCRIPT $ARGS"

echo ""
echo "ğŸ” ç”Ÿæˆçš„DeepSpeedè®­ç»ƒå‘½ä»¤:"
echo "=================================================="
echo "$FULL_CMD"
echo "=================================================="

echo ""
echo "ğŸ“‹ å‘½ä»¤åˆ†è§£:"
echo "ğŸ”¥ DeepSpeedéƒ¨åˆ†: $DEEPSPEED_CMD"
echo "ğŸ“„ è®­ç»ƒè„šæœ¬: $TRAIN_SCRIPT"
echo "âš™ï¸  è®­ç»ƒå‚æ•°: $ARGS"

echo ""
echo "ğŸ§ª æµ‹è¯•--helpè¾“å‡º (ä»…éªŒè¯å‚æ•°è§£æ)..."
echo "python $TRAIN_SCRIPT --help"

echo ""
echo "âœ… DeepSpeedå‘½ä»¤æ„å»ºæµ‹è¯•å®Œæˆ!"
echo "ğŸ“ æ‚¨å¯ä»¥å¤åˆ¶ä¸Šè¿°å‘½ä»¤æ‰‹åŠ¨æ‰§è¡Œï¼Œæˆ–ç›´æ¥è¿è¡Œ ./fast_train.sh"
