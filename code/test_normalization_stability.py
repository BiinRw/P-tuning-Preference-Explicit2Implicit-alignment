#!/usr/bin/env python3
"""
æ•°å€¼ç¨³å®šæ€§è¯Šæ–­è„šæœ¬ - ç”¨äºåˆ†æå½’ä¸€åŒ–ç­–ç•¥ä¸­çš„NaNé—®é¢˜
"""

import torch
import numpy as np
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('/home/wangbinrui/research_projects/llama_rlhf/code')

def test_normalization_stability():
    """æµ‹è¯•å„ç§å½’ä¸€åŒ–ç­–ç•¥çš„æ•°å€¼ç¨³å®šæ€§"""
    
    print("ğŸ” æ•°å€¼ç¨³å®šæ€§è¯Šæ–­å¼€å§‹...")
    print("=" * 60)
    
    # åˆ›å»ºå„ç§å¯èƒ½çš„é—®é¢˜æ•°æ®
    test_cases = [
        {
            "name": "æ­£å¸¸æ•°æ®",
            "base": torch.randn(8) * 0.5,
            "pref": torch.randn(8) * 2.0
        },
        {
            "name": "æå°æ•°å€¼",
            "base": torch.randn(8) * 1e-6,
            "pref": torch.randn(8) * 1e-5
        },
        {
            "name": "æå¤§æ•°å€¼",
            "base": torch.randn(8) * 100,
            "pref": torch.randn(8) * 200
        },
        {
            "name": "æ•°å€¼å·®å¼‚æå¤§",
            "base": torch.randn(8) * 1e-6,
            "pref": torch.randn(8) * 100
        },
        {
            "name": "åŒ…å«é›¶å€¼",
            "base": torch.tensor([0.0, 0.0, 1e-8, 1e-7, 0.1, 0.2, 0.0, 0.0]),
            "pref": torch.randn(8) * 2.0
        },
        {
            "name": "æ ‡å‡†å·®æ¥è¿‘é›¶",
            "base": torch.tensor([0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001]),
            "pref": torch.randn(8) * 2.0
        }
    ]
    
    strategies = [
        "none", "scale_to_base", "magnitude_preserve", 
        "robust_scaling", "percentile_scaling", "dynamic_range"
    ]
    
    for case in test_cases:
        print(f"\nğŸ“Š æµ‹è¯•ç”¨ä¾‹: {case['name']}")
        print("-" * 40)
        
        base_data = case["base"]
        pref_data = case["pref"]
        
        print(f"åŸå§‹baseæ•°æ®: {base_data}")
        print(f"åŸå§‹prefæ•°æ®: {pref_data}")
        print(f"baseèŒƒå›´: [{base_data.min():.6f}, {base_data.max():.6f}], std: {base_data.std():.6f}")
        print(f"prefèŒƒå›´: [{pref_data.min():.6f}, {pref_data.max():.6f}], std: {pref_data.std():.6f}")
        
        for strategy in strategies:
            try:
                normalized_base, normalized_pref = apply_normalization(
                    base_data.clone(), pref_data.clone(), strategy
                )
                
                # æ£€æŸ¥NaNå’ŒInf
                has_nan = torch.isnan(normalized_base).any() or torch.isnan(normalized_pref).any()
                has_inf = torch.isinf(normalized_base).any() or torch.isinf(normalized_pref).any()
                
                status = "âœ…" if not (has_nan or has_inf) else "âŒ"
                
                print(f"  {status} {strategy:20s}: base=[{normalized_base.min():.3f}, {normalized_base.max():.3f}], pref=[{normalized_pref.min():.3f}, {normalized_pref.max():.3f}]", end="")
                
                if has_nan:
                    print(" [NaNæ£€æµ‹]", end="")
                if has_inf:
                    print(" [Infæ£€æµ‹]", end="")
                print()
                
            except Exception as e:
                print(f"  âŒ {strategy:20s}: é”™è¯¯ - {str(e)}")

def apply_normalization(pi_logratios_raw, pi_pref_logratios_raw, normalize_strategy):
    """åº”ç”¨å½’ä¸€åŒ–ç­–ç•¥"""
    
    if normalize_strategy == "magnitude_preserve":
        # ä¿æŒæ•°å€¼å¤§å°çš„å½’ä¸€åŒ–ï¼šåªå¯¹é½æ–¹å‘å’Œç›¸å¯¹å¤§å°ï¼Œä¿æŒç»å¯¹æ•°å€¼èŒƒå›´
        # æ·»åŠ æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥
        base_std = pi_logratios_raw.std() + 1e-8
        pref_std = pi_pref_logratios_raw.std() + 1e-8
        
        # ä¿æŒè¾ƒå¤§çš„æ ‡å‡†å·®ä½œä¸ºç›®æ ‡èŒƒå›´ï¼Œä½†é™åˆ¶æœ€å¤§æ”¾å¤§å€æ•°
        target_std = torch.max(base_std, pref_std)
        
        # é™åˆ¶æ”¾å¤§å€æ•°ï¼Œé¿å…æ•°å€¼çˆ†ç‚¸
        max_scale_factor = 10.0  # é™åˆ¶æœ€å¤§æ”¾å¤§10å€
        base_scale_factor = torch.clamp(target_std / base_std, min=0.1, max=max_scale_factor)
        pref_scale_factor = torch.clamp(target_std / pref_std, min=0.1, max=max_scale_factor)
        
        # ç¼©æ”¾åˆ°ç›¸åŒçš„æ ‡å‡†å·®ï¼Œä½†ä¿æŒå‡å€¼
        pi_logratios = pi_logratios_raw * base_scale_factor
        pi_pref_logratios = pi_pref_logratios_raw * pref_scale_factor
        
        # é¢å¤–çš„æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥
        pi_logratios = torch.clamp(pi_logratios, min=-100, max=100)
        pi_pref_logratios = torch.clamp(pi_pref_logratios, min=-100, max=100)
        
    elif normalize_strategy == "scale_to_base":
        # å°†preference logratiosç¼©æ”¾åˆ°ä¸base logratiosç›¸åŒçš„é‡çº§
        base_scale = pi_logratios_raw.abs().mean() + 1e-8
        pref_scale = pi_pref_logratios_raw.abs().mean() + 1e-8
        scale_factor = base_scale / pref_scale
        
        pi_logratios = pi_logratios_raw
        pi_pref_logratios = pi_pref_logratios_raw * scale_factor
        
    elif normalize_strategy == "robust_scaling":
        # é²æ£’ç¼©æ”¾ï¼šä¿æŒæ•°å€¼èŒƒå›´çš„åŒæ—¶å¯¹é½åˆ†å¸ƒ
        base_median = torch.median(pi_logratios_raw)
        pref_median = torch.median(pi_pref_logratios_raw)
        
        base_q75 = torch.quantile(pi_logratios_raw, 0.75)
        base_q25 = torch.quantile(pi_logratios_raw, 0.25)
        base_iqr = base_q75 - base_q25 + 1e-8
        
        pref_q75 = torch.quantile(pi_pref_logratios_raw, 0.75)
        pref_q25 = torch.quantile(pi_pref_logratios_raw, 0.25)
        pref_iqr = pref_q75 - pref_q25 + 1e-8
        
        # ç¼©æ”¾åˆ°ç›¸åŒçš„å››åˆ†ä½è·
        scale_factor = base_iqr / pref_iqr
        
        pi_logratios = pi_logratios_raw
        pi_pref_logratios = (pi_pref_logratios_raw - pref_median) * scale_factor + base_median
        
    elif normalize_strategy == "percentile_scaling":
        # ç™¾åˆ†ä½ç¼©æ”¾ï¼šåŸºäº90%åˆ†ä½æ•°è¿›è¡Œç¼©æ”¾ï¼Œé¿å…æå€¼å½±å“
        base_p90 = torch.quantile(torch.abs(pi_logratios_raw), 0.9) + 1e-8
        pref_p90 = torch.quantile(torch.abs(pi_pref_logratios_raw), 0.9) + 1e-8
        
        scale_factor = base_p90 / pref_p90
        
        pi_logratios = pi_logratios_raw
        pi_pref_logratios = pi_pref_logratios_raw * scale_factor
        
    elif normalize_strategy == "dynamic_range":
        # åŠ¨æ€èŒƒå›´ä¿æŒï¼šä¿æŒåŸå§‹æ•°å€¼çš„åŠ¨æ€èŒƒå›´
        base_range = pi_logratios_raw.max() - pi_logratios_raw.min() + 1e-8
        pref_range = pi_pref_logratios_raw.max() - pi_pref_logratios_raw.min() + 1e-8
        
        # é€‰æ‹©è¾ƒå¤§çš„èŒƒå›´ä½œä¸ºç›®æ ‡
        target_range = torch.max(base_range, pref_range)
        
        # ç¼©æ”¾åˆ°ç›®æ ‡èŒƒå›´
        base_scale = target_range / base_range
        pref_scale = target_range / pref_range
        
        pi_logratios = pi_logratios_raw * base_scale
        pi_pref_logratios = pi_pref_logratios_raw * pref_scale
        
    else:  # "none" or default
        # ä¸è¿›è¡Œå½’ä¸€åŒ–ï¼Œåªæ˜¯ç®€å•clamp
        pi_logratios = torch.clamp(pi_logratios_raw, min=-10, max=10)
        pi_pref_logratios = torch.clamp(pi_pref_logratios_raw, min=-10, max=10)
    
    return pi_logratios, pi_pref_logratios

def recommend_strategy():
    """æ¨èç¨³å®šçš„å½’ä¸€åŒ–ç­–ç•¥"""
    print("\nğŸ¯ æ¨èç­–ç•¥")
    print("=" * 60)
    print("åŸºäºæ•°å€¼ç¨³å®šæ€§åˆ†æï¼Œæ¨èä½¿ç”¨ä»¥ä¸‹ç­–ç•¥ï¼š")
    print()
    print("1. ğŸ¥‡ robust_scaling - æœ€ç¨³å®šï¼Œå¯¹å¼‚å¸¸å€¼é²æ£’")
    print("2. ğŸ¥ˆ percentile_scaling - åŸºäºåˆ†ä½æ•°ï¼Œé¿å…æå€¼å½±å“") 
    print("3. ğŸ¥‰ none - ç®€å•clampï¼Œæœ€ä¿å®ˆ")
    print()
    print("âŒ é¿å…ä½¿ç”¨ï¼š")
    print("- magnitude_preserve (åŸç‰ˆ) - å¯èƒ½å¯¼è‡´æ•°å€¼çˆ†ç‚¸")
    print("- scale_to_base - åœ¨æ•°å€¼å·®å¼‚å¤§æ—¶ä¸ç¨³å®š")
    print()
    print("âœ… magnitude_preserve (ä¿®å¤ç‰ˆ) - å·²æ·»åŠ æ•°å€¼ç¨³å®šæ€§ä¿æŠ¤")

if __name__ == "__main__":
    test_normalization_stability()
    recommend_strategy()
