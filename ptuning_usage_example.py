#!/usr/bin/env python3
"""
ç¤ºä¾‹ï¼šå¦‚ä½•ä½¿ç”¨æ–°å¢çš„P-tuningåŠŸèƒ½

è¿™ä¸ªè„šæœ¬å±•ç¤ºäº†å¦‚ä½•åˆ›å»ºå’Œä½¿ç”¨prompt embeddingsè¿›è¡ŒP-tuningæ¨ç†
"""

import torch
import os

def create_sample_prompt_embedding():
    """åˆ›å»ºä¸€ä¸ªç¤ºä¾‹çš„prompt embeddingæ–‡ä»¶"""
    
    # åˆ›å»ºç¤ºä¾‹prompt embeddings
    # å‡è®¾æˆ‘ä»¬æœ‰5ä¸ªprompt tokensï¼Œæ¯ä¸ªtokençš„embeddingç»´åº¦æ˜¯4096 (LLaMAçš„hidden size)
    prompt_length = 5
    hidden_size = 4096
    
    # éšæœºåˆå§‹åŒ–prompt embeddings (åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œè¿™äº›åº”è¯¥æ˜¯è®­ç»ƒå¥½çš„)
    prompt_embeddings = torch.randn(prompt_length, hidden_size)
    
    # ä¿å­˜ä¸º.ptæ–‡ä»¶
    save_path = "/tmp/sample_prompt_embeddings.pt"
    torch.save(prompt_embeddings, save_path)
    
    print(f"âœ“ åˆ›å»ºäº†ç¤ºä¾‹prompt embeddingæ–‡ä»¶: {save_path}")
    print(f"  - Prompt length: {prompt_length}")
    print(f"  - Hidden size: {hidden_size}")
    print(f"  - Shape: {prompt_embeddings.shape}")
    
    return save_path

def create_dict_format_prompt_embedding():
    """åˆ›å»ºå­—å…¸æ ¼å¼çš„prompt embeddingæ–‡ä»¶ (æ›´å¸¸è§çš„ä¿å­˜æ ¼å¼)"""
    
    prompt_length = 10
    hidden_size = 4096
    
    # åˆ›å»ºprompt embeddings
    prompt_embeddings = torch.randn(prompt_length, hidden_size)
    
    # ä¿å­˜ä¸ºå­—å…¸æ ¼å¼ (è¿™æ˜¯æ›´å¸¸è§çš„ä¿å­˜æ–¹å¼)
    embedding_dict = {
        'prompt_embeddings': prompt_embeddings,
        'prompt_length': prompt_length,
        'hidden_size': hidden_size,
        'model_name': 'sample_model',
        'training_steps': 1000,
    }
    
    save_path = "/tmp/sample_prompt_embeddings_dict.pt"
    torch.save(embedding_dict, save_path)
    
    print(f"âœ“ åˆ›å»ºäº†å­—å…¸æ ¼å¼çš„prompt embeddingæ–‡ä»¶: {save_path}")
    print(f"  - åŒ…å«å…ƒæ•°æ®çš„å®Œæ•´ä¿å­˜æ ¼å¼")
    
    return save_path

def show_usage_examples():
    """æ˜¾ç¤ºä½¿ç”¨ç¤ºä¾‹"""
    
    print("\n" + "="*60)
    print("ğŸš€ P-tuningåŠŸèƒ½ä½¿ç”¨ç¤ºä¾‹")
    print("="*60)
    
    # åˆ›å»ºç¤ºä¾‹æ–‡ä»¶
    simple_path = create_sample_prompt_embedding()
    dict_path = create_dict_format_prompt_embedding()
    
    print(f"\nğŸ“ ä½¿ç”¨æ–¹æ³•:")
    print(f"åŸæ¥çš„å‘½ä»¤:")
    print(f"python3 gen_hh_answers.py \\")
    print(f"    --model-path /path/to/your/model \\")
    print(f"    --model-id your-model-name")
    
    print(f"\nğŸ†• æ–°å¢P-tuningæ”¯æŒåçš„å‘½ä»¤:")
    print(f"python3 gen_hh_answers.py \\")
    print(f"    --model-path /path/to/your/model \\")
    print(f"    --model-id your-model-name \\")
    print(f"    --prompt-embedding-path {simple_path}")
    
    print(f"\næˆ–è€…ä½¿ç”¨å­—å…¸æ ¼å¼çš„embedding:")
    print(f"python3 gen_hh_answers.py \\")
    print(f"    --model-path /path/to/your/model \\")
    print(f"    --model-id your-model-name \\")
    print(f"    --prompt-embedding-path {dict_path}")
    
    print(f"\nğŸ’¡ å®Œæ•´ç¤ºä¾‹å‘½ä»¤ (ä½¿ç”¨å…¶ä»–å‚æ•°):")
    print(f"python3 gen_hh_answers.py \\")
    print(f"    --model-path /path/to/llama2-7b \\")
    print(f"    --model-id llama2-7b-ptuned \\")
    print(f"    --bench-name hh_bench \\")
    print(f"    --prompt-embedding-path {dict_path} \\")
    print(f"    --max-new-token 512 \\")
    print(f"    --num-choices 1")
    
    print(f"\nğŸ“‹ P-tuningç‰¹æ€§:")
    print(f"âœ“ è‡ªåŠ¨æ£€æµ‹prompt embeddingæ–‡ä»¶æ ¼å¼ (tensoræˆ–dict)")
    print(f"âœ“ æ”¯æŒä¸åŒçš„embeddingç»´åº¦")
    print(f"âœ“ å…¼å®¹åŸæœ‰çš„æ‰€æœ‰å‚æ•°")
    print(f"âœ“ å¯é€‰åŠŸèƒ½ - ä¸å½±å“åŸæœ‰ç”¨æ³•")
    print(f"âœ“ æ”¯æŒå¤šGPUæ¨ç†")
    
    print(f"\nğŸ“ Prompt Embeddingæ–‡ä»¶æ ¼å¼:")
    print(f"1. ç®€å•tensoræ ¼å¼: torch.save(embeddings, 'file.pt')")
    print(f"   - embeddings shape: [prompt_length, hidden_size]")
    print(f"2. å­—å…¸æ ¼å¼: torch.save({{'prompt_embeddings': embeddings, ...}}, 'file.pt')")
    print(f"   - å¯ä»¥åŒ…å«é¢å¤–çš„å…ƒæ•°æ®")
    
    print(f"\nğŸ”§ å¦‚ä½•è®­ç»ƒP-tuning prompt embeddings:")
    print(f"1. ä½¿ç”¨è®­ç»ƒè„šæœ¬è®­ç»ƒprompt embeddings")
    print(f"2. ä¿å­˜è®­ç»ƒå¥½çš„embeddingsåˆ°.pt/.pthæ–‡ä»¶")
    print(f"3. ä½¿ç”¨--prompt-embedding-pathå‚æ•°åŠ è½½è¿›è¡Œæ¨ç†")

if __name__ == "__main__":
    show_usage_examples()
